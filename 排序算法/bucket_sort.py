""""
桶排序：

原理：
    将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。
    桶内排序之后，再把每个桶里的数据按顺序依次取出，组成的序列就是有序的了。

执行效率：
    时间复杂度： 最好O(n)
        如果待排序数据有n个，我们把它们【均匀】地划分到m个桶内，每个桶里就有 k = n / m 个元素。
        在每个桶里使用快速排序，时间复杂度是O(k*logk)。m个桶排序的时间复杂度就是O(m * k * logk)。带入k = n/m得 O(n*log n/m)
        当桶的个数m接近数据个数n时，log(n/m)是一个非常小的常量，这个时候桶排序接近O(n)。
        因此时间复杂度最好是O(n)，但是对待排序数据的要求非常苛刻！！

        数据要求：
            1）待排序数据需要很容易就能划分成m个桶，并且桶与桶之间有着天然的大小顺序。一般来说划分有一定的意义。
            2）数据在各个桶之间的分布是比较平均的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那么log(n/m)就不是常量级了。
               在极端情况下，如果数据都被划分到一个桶里，即m=1，那么就退化为O(nlogn)的排序算法了。
适用场景：
    适合用在外部排序中。
    数据存储在外部磁盘上，【数据量大】，内存有限，无法将所有数据全部加载到内存中。

    比如说我们有 10GB 的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百 MB，没办法一次性把 10GB 的数据都加载到内存中。
    我们可以先扫描一遍文件，看订单金额所处的数据范围。
    假设经过扫描之后我们得到，订单金额最小是 1 元，最大是 10 万元。我们将所有订单根据金额划分到 100 个桶里，
    第一个桶我们存储金额在 1 元到 1000 元之内的订单，第二桶存储金额在 1001 元到 2000 元之内的订单，以此类推。
    每一个桶对应一个文件，并且按照金额范围的大小顺序编号命名（00，01，02…99）。
    理想的情况下，如果订单金额在 1 到 10 万之间均匀分布，那订单会被均匀划分到 100 个文件中，
    每个小文件中存储大约 100MB 的订单数据，我们就可以将这 100 个小文件依次放到内存中，用快排来排序。
    等所有文件都排好序之后，我们只需要按照文件编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大排序的订单数据了。
    不过，你可能也发现了，订单按照金额在 1 元到 10 万元之间并不一定是均匀分布的 ，所以 10GB 订单数据是无法均匀地被划分到 100 个文件中的。
    有可能某个金额区间的数据特别多，划分之后对应的文件就会很大，没法一次性读入内存。
    这又该怎么办呢？针对这些划分之后还是比较大的文件，我们可以继续划分，
    比如，订单金额在 1 元到 1000 元之间的比较多，我们就将这个区间继续划分为 10 个小区间，1 元到 100 元，101 元到 200 元，201 元到 300 元…901 元到 1000 元。
    如果划分之后，101 元到 200 元之间的订单还是太多，无法一次性读入内存，那就继续再划分，直到所有的文件都能读入内存为止。



二、桶排序（Bucket sort）
1.算法原理：
1）将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行快速排序。
2）桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。
2.使用条件
1）要排序的数据需要很容易就能划分成m个桶，并且桶与桶之间有着天然的大小顺序。
2）数据在各个桶之间分布是均匀的。
3.适用场景
1）桶排序比较适合用在外部排序中。
2）外部排序就是数据存储在外部磁盘且数据量大，但内存有限无法将整个数据全部加载到内存中。
4.应用案例
1）需求描述：
有10GB的订单数据，需按订单金额（假设金额都是正整数）进行排序
但内存有限，仅几百MB
2）解决思路：
扫描一遍文件，看订单金额所处数据范围，比如1元-10万元，那么就分100个桶。
第一个桶存储金额1-1000元之内的订单，第二个桶存1001-2000元之内的订单，依次类推。
每个桶对应一个文件，并按照金额范围的大小顺序编号命名（00，01，02，…，99）。
将100个小文件依次放入内存并用快排排序。
所有文件排好序后，只需按照文件编号从小到大依次读取每个小文件并写到大文件中即可。
3）注意点：若单个文件无法全部载入内存，则针对该文件继续按照前面的思路进行处理即可。

"""